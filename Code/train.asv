% We're just using training images

% we don't find the best rectangle filter, but the best classifer when
% boosting

s = filesep; % This gets the file separator character from the  system
training_faces = strcat(training_directory, '\training_faces');
training_nonfaces = strcat(training_directory, '\training_nonfaces');
other_code = strcat(code_directory, '\given');
addpath([other_code s '00_common' s '00_detection'])
addpath([other_code s '00_common' s '00_images'])
addpath([other_code s '00_common' s '00_utilities'])
addpath(other_code)
addpath(training_faces)
addpath(training_nonfaces)

cd(code_directory)


best_boosted_classifer = zeros(0, 3);

%%

number_faces = 5;
number_nonfaces = 2;

face_images = dir(fullfile(training_faces,'*.bmp'));
nonface_images = dir(fullfile(training_nonfaces,'*.jpg'));

%nfiles = length(imagefiles);
faces = zeros(63, 57, number_faces);
for i = 1:number_faces
  filename = fullfile(training_faces,face_images(i).name);
  tempface = read_gray(filename);
  faces(:,:,i) = tempface(26:88, 22:78);
end

face_pool = zeros(63, 57, number_faces);
for i = 1:size(face_images, 1)
  filename = fullfile(training_faces,face_images(i).name);
  tempface = read_gray(filename);
  face_pool(:,:,i) = tempface(26:88, 22:78);
end
%figure(1)
%imshow(faces(:,:,27),[]);

nonfaces = zeros(size(faces,1), size(faces,2), number_nonfaces);
num_subwindows = 5;
non_faces_index = 1;
for i = 1:number_nonfaces
    filename = fullfile(training_nonfaces,nonface_images(i).name);
    temp_nonface = read_gray(filename);
    for j = 1:num_subwindows
        offset_x = floor((size(temp_nonface,1)-3*size(nonfaces,1)).*rand(1,1)+size(nonfaces,1));
        offset_y = floor((size(temp_nonface,2)-3*size(nonfaces,2)).*rand(1,1)+size(nonfaces,2));
        nonfaces(:,:,non_faces_index) = temp_nonface(19+offset_x:81+offset_x, 22+offset_y:78+offset_y);
        non_faces_index = non_faces_index+1;
    end
end

nonface_pool = zeros(size(faces,1), size(faces,2), size(nonface_images,1) * num_subwindows);
for i = 1:size(nonface_images,1)
    filename = fullfile(training_nonfaces,nonface_images(i).name);
    temp_nonface = read_gray(filename);
    for j = 1:num_subwindows
        offset_x = floor((size(temp_nonface,1)-3*size(nonface_pool,1)).*rand(1,1)+size(nonface_pool,1));
        offset_y = floor((size(temp_nonface,2)-3*size(nonface_pool,2)).*rand(1,1)+size(nonface_pool,2));
        nonface_pool(:,:,non_faces_index) = temp_nonface(19+offset_x:81+offset_x, 22+offset_y:78+offset_y);
        non_faces_index = non_faces_index+1;
    end
end


dimensions = [size(faces(:,:,1),1), size(faces(:,:,1),2)];%[100, 100];
% traing_face dimension is 100 x 100

% We have 5 thresholds per pixel
% so 10000 * 5 = 50000 classifers

%%

%dimensions = [1000, 1000];

% bootstrapping, adding wrong_faces into array of faces to increase
% strength of face detector on extreme cases

% create every weak classifer here in a for loop

%number = floor(dimensions(1) * dimensions(2) / 10);


%{
% evaluate within this function until function is met
        [boosted_classifier, weak_classifiers] = bootstrapping_adaboost(dimensions,faces,nonfaces,face_pool,nonface_pool,number_faces,number_nonfaces);



while (delta_wrong_face > 20 && delta_wrong_nonface > 20)
    old_num_wrong_nonface = num_wrong_nonface;
    old_num_wrong_face = num_wrong_face;
    
    weak_classifiers = create_weak_classifers(weak_classifiers,dimensions, number);
    
    %% create_responses
    responses = create_responses(weak_classifiers, faces, nonfaces, face_pool, ...
                                    nonface_pool,number_faces,number_nonfaces, dimensions);
    
    boosted_classifier_num = boosted_classifier_num + 5;
    boosted_classifier = AdaBoost(responses, labels, boosted_classifier_num);

    
    %% Evaluate boosted classifer
    [detection_rate, false_positive_rate] = eval_boosted_classifer(boosted_classifier, weak_classifiers, faces, nonfaces, face_pool, nonface_pool, ...
                                    number_faces,number_nonfaces, dimensions, boosted_classifier_num);
    
end
%} 



number = 1000;
weak_classifiers = cell(1, 0);

rounds = 20;
%for round = 1: rounds

old_num_wrong_nonface = -1;
old_num_wrong_face = -1;
num_wrong_face = 0;
num_wrong_nonface = 0;
delta_wrong_face = inf;
delta_wrong_nonface = inf;
boosted_classifier_num = 0;
F = [1.0];
D = [1.0];
n = [0];
i = 1;
f = 0.5;
d = 0.6;
ftarget = 0.5;

boosted_classes = cell(1, 0);

while(F(i) > ftarget)
    temp_decrease = 0.1;
    
    i = i + 1; 
    
    n = [n, 0];
    F = [F, (F(i - 1))];
    
    while(F(i) > f * F(i - 1))
        % use P and N to train a classifier with n(i) features using AdaBoost
        
        disp("training false_positive_rate = " + F(i)) 
        
        n(i) = n(i) + 1;
        D = [D, 0];
		
        % Create weak classifers
		weak_classifiers = create_weak_classifers(weak_classifiers,dimensions, number);
		
		% create_responses
		[responses, labels] = create_responses(weak_classifiers, faces, nonfaces, face_pool, ...
										nonface_pool,number_faces,number_nonfaces, dimensions);
		
		boosted_classifier_num = n(i);
		boosted_classifier = AdaBoost(responses, labels, boosted_classifier_num);
		
        D(i) = 0;
        
        classifer_index = 1;
        
        eval_round = 1;
        detection_rate = 0;
        
        while(D(i) < (d * D(i - 1)) && eval_round ~= 5)
           
           eval_round = eval_round + 1; 
            
           disp("evaluating dectection_rate = " + detection_rate)
           % Evaluate current cascaded classifier on validation set to determine F(i) and D(i)
           [detection_rate, false_positive_rate] = eval_boosted_classifer(boosted_classifier, weak_classifiers, faces, nonfaces, face_pool, nonface_pool, ...
										number_faces,number_nonfaces, dimensions, boosted_classifier_num);
                                    
           D(i) = detection_rate;
           F(i) = false_positive_rate;
           
           % decrease threshold for the ith classifier (i.e. how many weak classifiers need to accept for strong classifier to accept)
           % until the current cascaded classifier has a detection rate of at least d Ã— D(i-1) (this also affects F(i))
           
           if(D(i) < (d * D(i - 1)))
               boosted_classifier(classifer_index, 3) = boosted_classifier(classifer_index, 3) + 10;
               classifer_index = classifer_index + 1;
               if(classifer_index == size(classifer_index, 1)+1)
                   classifer_index = 1;
               end
           end
        end
        
        %F(i) = F(i) - temp_decrease;
        
    end

    disp("created layer")
    for classifer_index = 1: size(boosted_classifier, 1)
        
    end
    boosted_classes = cat(2, boosted_classes, {boosted_classifier});
    N = [];
    if(F(i) > ftarget)
        %evaluate the current cascaded detector on the set of non-face 
        %images and put any false detections into the set N.
        
        % This is probably bootstrapping
        
    end
 end

        

%boosted_classifier = bootstrapping_adaboost(dimensions,faces,nonfaces,face_pool,nonface_pool,number_faces,number_nonfaces);
%}

save boosted_classifier boosted_classifier
save weak_classifiers weak_classifiers
save boosted_classifier_num boosted_classifier_num
save classife boosted_classes

%%
%saved_boosetd_classifier = boosted_classifier;
%boosted_classifier = saved_boosetd_classifier;

% repeat training N times and keep only the classifers with positive alphas, and
% replace the classifers with negative alphas, with new weak classifers
%%
%{
for i = 1: 5
    best_boosted_classifer_index = find(max(boosted_classifier(:, 2)) == boosted_classifier(:, 2), 1);
    best_boosted_classifer(i, :) = boosted_classifier(best_boosted_classifer_index, :);
    
    best_boosted_classifer = cat(1, best_boosted_classifer, boosted_classifier(best_boosted_classifer_index, :));
    
    boosted_classifier(best_boosted_classifer_index, :) = -inf;
    
end
%}
%%

%kept_classifiers = cell(1, boosted_classifier_num);
%for i = 1:boosted_classifier_num
%    kept_classifiers{i} = weak_classifiers{boosted_classifier(i,1)};
%end

%%
%{
num_wrong_nonface = 0;

for i = 1:size(nonfaces,3)
    prediction = boosted_predict(nonfaces(:, :, i), boosted_classifier, weak_classifiers, boosted_classifier_num);
    if (prediction > 0)
        num_wrong_nonface = num_wrong_nonface + 1;
    end
end
%}
% Each time we create a weak classifer, we use generate_classifer

% Every weak classifer has soft classifer per threshold

% Top 1000 responses will become the  classifer

% get integral skin image


% generate classifer